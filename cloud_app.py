import streamlit as st
import os
import sys

# --- å¯¼å…¥æ ¸å¿ƒåº“ ---
try:
    from langchain_community.document_loaders import PyPDFLoader
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    from langchain_community.vectorstores import FAISS
    from langchain_community.embeddings import HuggingFaceEmbeddings
    from langchain_openai import ChatOpenAI
    from langchain.chains import RetrievalQA
except Exception as e:
    st.error(f"ç¯å¢ƒåŠ è½½å¤±è´¥: {e}")
    st.stop()

# --- é¡µé¢è®¾ç½® ---
st.set_page_config(page_title="äº‘ç«¯çŸ¥è¯†åº“", page_icon="â˜ï¸")
st.title("â¤ å°èŒ¹ä¸“å±ç§‘ä¸€çŸ¥è¯†åº“é—®ç­”åŠ©æ‰‹")

# --- æ ¸å¿ƒé…ç½® ---
DATA_FOLDER = "knowledge"  # ä½ çš„ PDF æ–‡ä»¶å¤¹åå­—

# --- è·å– API Key (ä¼˜å…ˆä»äº‘ç«¯é€šè¿‡ Secrets è·å–ï¼Œå¦‚æœæ²¡æœ‰åˆ™è®©ç”¨æˆ·å¡«) ---
# è¿™æ ·ä½ å¯ä»¥æŠŠ Key è—åœ¨åå°ï¼Œå®¢æˆ·ä¸ç”¨å¡«ï¼Œä¹Ÿçœ‹ä¸åˆ°
if "DEEPSEEK_API_KEY" in st.secrets:
    api_key = st.secrets["DEEPSEEK_API_KEY"]
else:
    api_key = st.sidebar.text_input("è¯·è¾“å…¥ DeepSeek API Key", type="password")

# --- ä¾§è¾¹æ å±•ç¤º ---
with st.sidebar:
    st.markdown("### ğŸ“š å·²åŠ è½½æ–‡æ¡£")
    if os.path.exists(DATA_FOLDER):
        files = [f for f in os.listdir(DATA_FOLDER) if f.endswith('.pdf')]
        for f in files:
            st.text(f"ğŸ“„ {f}")
    else:
        st.error(f"æœªæ‰¾åˆ° {DATA_FOLDER} æ–‡ä»¶å¤¹")

# --- æ ¸å¿ƒå‡½æ•° ---
@st.cache_resource
def load_knowledge_base():
    # 1. æ‰«ææ–‡ä»¶
    if not os.path.exists(DATA_FOLDER):
        return None
    
    files = [f for f in os.listdir(DATA_FOLDER) if f.endswith('.pdf')]
    if not files:
        return None
    
    all_documents = []
    print(f"æ­£åœ¨åŠ è½½ {len(files)} ä¸ªæ–‡ä»¶...")
    
    # 2. åŠ è½½
    for filename in files:
        file_path = os.path.join(DATA_FOLDER, filename)
        try:
            loader = PyPDFLoader(file_path)
            docs = loader.load()
            all_documents.extend(docs)
        except Exception as e:
            print(f"åŠ è½½å¤±è´¥: {filename}")

    # 3. åˆ‡åˆ†
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    splits = text_splitter.split_documents(all_documents)

    # 4. å‘é‡åŒ– (äº‘ç«¯ä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼Œé€Ÿåº¦å¾ˆå¿«)
    embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    
    # 5. å­˜å…¥ FAISS
    vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)
    
    return vectorstore

# --- ä¸»é€»è¾‘ ---
if not api_key:
    st.warning("è¯·åœ¨ä¾§è¾¹æ è¾“å…¥ Keyï¼Œæˆ–åœ¨ Secrets ä¸­é…ç½®ã€‚")
    st.stop()

# åŠ è½½çŸ¥è¯†åº“
with st.spinner("æ­£åœ¨å¯åŠ¨äº‘ç«¯å¼•æ“..."):
    vectorstore = load_knowledge_base()

if vectorstore:
    # å‡†å¤‡é—®ç­”é“¾
    llm = ChatOpenAI(
        api_key=api_key,
        base_url="https://api.deepseek.com",
        model="deepseek-chat",
        temperature=0
    )
    retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
    qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)
    
    st.success("âœ… ç³»ç»Ÿå°±ç»ªï¼")
    
    # èŠå¤©ç•Œé¢
    question = st.text_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼š", placeholder="å…³äºè¿™äº›æ–‡æ¡£ï¼Œä½ æƒ³é—®ä»€ä¹ˆï¼Ÿ")
    
    if question:
        with st.spinner("AI æ­£åœ¨æ€è€ƒ..."):
            result = qa_chain.invoke({"query": question})
            st.write("### ğŸ¤– å›ç­”ï¼š")
            st.info(result['result'])
else:
    st.error("çŸ¥è¯†åº“ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ GitHub ä»“åº“ä¸­æ˜¯å¦ä¸Šä¼ äº† PDF æ–‡ä»¶ã€‚")